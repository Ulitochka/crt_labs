{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инициализируем реальные данные из validate и заодно инициализируем их среднее по клипам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "colls = ['file_path', 'valence', 'arousal']\n",
    "drop_colls = []\n",
    "for i in range(137):\n",
    "    colls.append('mark_{}'.format(i))\n",
    "    drop_colls.append('mark_{}'.format(i))\n",
    "actual_data = pd.read_table('valid_data_with_landmarks.txt', names = colls, delim_whitespace=True)\n",
    "actual_data.drop(columns = drop_colls, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_unix(path):\n",
    "    file = path.split('/')[1:]\n",
    "    file = '/'.join(file)\n",
    "    return '\\\\'+file[:file.find('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip(path):\n",
    "    file = path.split('\\\\')[:-1]\n",
    "    file = '/'.join(file)\n",
    "    return '\\\\'+file[:file.find('.')]\n",
    "\n",
    "actual_data['file_path'] = actual_data['file_path'].apply(get_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def means(df):\n",
    "    return df.groupby('file_path', sort = False).mean().reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_data_mean = means(actual_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считаем модели Ивана"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аудио_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_test_I = pd.read_table('ready_models/results/AEmotion_Ivan_result_test.txt', delim_whitespace=True, names = ['file_path', 'valence_I1', 'arousal_I1'])\n",
    "audio_I = pd.read_table('ready_models/results/AEmotion_Ivan_result_valid.txt', delim_whitespace=True, names = ['file_path', 'valence_I1', 'arousal_I1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аудио_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_test_I2 = pd.read_table('ready_models/results/AEmotion_Ivan_result_test_3.txt', delim_whitespace=True, names = ['file_path', 'valence_I2', 'arousal_I2'])\n",
    "audio_I2 = pd.read_table('ready_models/results/AEmotion_Ivan_result_valid_3.txt', delim_whitespace=True, names = ['file_path', 'valence_I2', 'arousal_I2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель Михаила"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аудио_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_test_M = pd.read_table('ready_models/results/AEmotion_test_result.txt', delim_whitespace=True, names = ['file_path', 'valence_M1', 'arousal_M1'])\n",
    "audio_M = pd.read_table('ready_models/results/AEmotion_valid_result.txt', delim_whitespace=True, names = ['file_path', 'valence_M1', 'arousal_M1'])\n",
    "\n",
    "audio_test_M['file_path'] = audio_test_M['file_path'].apply(get_clip_unix)\n",
    "\n",
    "audio_M['file_path'] = audio_M['file_path'].apply(get_clip_unix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Видео_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_test_M = pd.read_table('ready_models/results/VEmotion_test_result.txt', delim_whitespace=True, names = ['file_path', 'valence_M2', 'arousal_M2'])\n",
    "video_M = pd.read_table('ready_models/results/VEmotion_valid_result.txt', delim_whitespace=True, names = ['file_path', 'valence_M2', 'arousal_M2'])\n",
    "\n",
    "video_test_M['file_path'] = video_test_M['file_path'].apply(get_clip_unix)\n",
    "\n",
    "video_M['file_path'] = video_M['file_path'].apply(get_clip_unix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_M = means(video_M)\n",
    "video_test_M = means(video_test_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем выгрузить активации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аудио 1 Михаил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ready_models/results/activations/audio_activations_test.pkl', 'rb')\n",
    "audio_feat_test = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "audio_feat_test = audio_feat_test.reshape((255, 1024))\n",
    "\n",
    "audio_feat_test = pd.DataFrame(audio_feat_test, columns = ['feat_{}'.format(i) for i in range(1024)])\n",
    "\n",
    "audio_test_M = pd.concat([audio_test_M, audio_feat_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ready_models/results/activations/audio_activations_valid.pkl', 'rb')\n",
    "audio_feat_valid = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "audio_feat_valid = audio_feat_valid.reshape((226, 1024))\n",
    "\n",
    "audio_feat_valid = pd.DataFrame(audio_feat_valid, columns = ['feat_{}'.format(i) for i in range(1024)])\n",
    "\n",
    "audio_M = pd.concat([audio_M, audio_feat_valid], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Видео 1 Михаил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(df):\n",
    "#     df = video_feat_test.loc[video_feat_test.file_path == '\\\\664ea0ccc_25/utterance_576']\n",
    "    return df.values[:,1:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ready_models/results/activations/video_activations_test.pkl', 'rb')\n",
    "video_feat_test = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "video_feat_test = video_feat_test.reshape(video_feat_test.shape[:2])\n",
    "video_feat_test = pd.DataFrame(video_feat_test, columns = ['feat_{}'.format(i) for i in range(video_feat_test.shape[1])])\n",
    "video_feat_test = pd.concat([actual_data.file_path, video_feat_test], axis = 1)\n",
    "\n",
    "features_df = video_feat_test.groupby('file_path').apply(PCA)\n",
    "features_df = pd.DataFrame({'feat' : features_df}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_test = []\n",
    "for val in features_df.values[1:]:\n",
    "    PCA_test.append(np.array(val[1:][0], dtype = 'float32').tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ready_models/results/activations/video_activations_valid.pkl', 'rb')\n",
    "video_feat_valid = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "video_feat_valid = video_feat_valid.reshape(video_feat_valid.shape[:2])\n",
    "video_feat_valid = pd.DataFrame(video_feat_valid, columns = ['feat_{}'.format(i) for i in range(video_feat_valid.shape[1])])\n",
    "video_feat_valid = pd.concat([actual_data.file_path, video_feat_valid], axis = 1)\n",
    "\n",
    "features_df = video_feat_valid.groupby('file_path').apply(PCA)\n",
    "features_df = pd.DataFrame({'feat' : features_df}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_train = []\n",
    "for val in features_df.values:\n",
    "    PCA_train.append(np.array(val[1:][0], dtype = 'float32').tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_fillna(data):\n",
    "    # Get lengths of each row of data\n",
    "    lens = np.array([len(i) for i in data])\n",
    "\n",
    "    # Mask of valid places in each row\n",
    "    mask = np.arange(lens.max()) < lens[:,None]\n",
    "\n",
    "    # Setup output array and put elements from data into masked positions\n",
    "    out = np.zeros(mask.shape, dtype=data.dtype)\n",
    "    out[mask] = np.concatenate(data)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_train = numpy_fillna(np.array(PCA_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "PCA = CCA(n_components=100)\n",
    "PCA_train = PCA.fit_transform(X = PCA_train, y=actual_data_mean[['valence', 'arousal']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_df = pd.DataFrame(PCA_train, columns = ['PCA_feat_{}'.format(i) for i in range(226)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_test = PCA.transform(PCA_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сделаем train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>valence_I2</th>\n",
       "      <th>arousal_I2</th>\n",
       "      <th>valence_M2</th>\n",
       "      <th>arousal_M2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\664ea0ccc_25/utterance_576</td>\n",
       "      <td>0.381382</td>\n",
       "      <td>0.100120</td>\n",
       "      <td>0.268021</td>\n",
       "      <td>0.148986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\bee9cd4cf_2/utterance_42</td>\n",
       "      <td>0.356596</td>\n",
       "      <td>0.272787</td>\n",
       "      <td>0.612218</td>\n",
       "      <td>0.434692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\664ea0ccc_31/utterance_718</td>\n",
       "      <td>0.407344</td>\n",
       "      <td>0.138530</td>\n",
       "      <td>0.458484</td>\n",
       "      <td>0.171215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\74de88564/utterance_7</td>\n",
       "      <td>0.386217</td>\n",
       "      <td>0.182176</td>\n",
       "      <td>0.085194</td>\n",
       "      <td>0.887938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\664ea0ccc_25/utterance_569</td>\n",
       "      <td>0.389408</td>\n",
       "      <td>0.151607</td>\n",
       "      <td>0.326090</td>\n",
       "      <td>0.167808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_path  valence_I2  arousal_I2  valence_M2  arousal_M2\n",
       "0  \\664ea0ccc_25/utterance_576    0.381382    0.100120    0.268021    0.148986\n",
       "1    \\bee9cd4cf_2/utterance_42    0.356596    0.272787    0.612218    0.434692\n",
       "2  \\664ea0ccc_31/utterance_718    0.407344    0.138530    0.458484    0.171215\n",
       "3       \\74de88564/utterance_7    0.386217    0.182176    0.085194    0.887938\n",
       "4  \\664ea0ccc_25/utterance_569    0.389408    0.151607    0.326090    0.167808"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = audio_I2.merge(video_M, on = 'file_path')\n",
    "# X_train = X_train.merge(audio_I2, on = 'file_path')\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>valence_I2</th>\n",
       "      <th>arousal_I2</th>\n",
       "      <th>valence_M2</th>\n",
       "      <th>arousal_M2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\664ea0ccc_25/utterance_580</td>\n",
       "      <td>0.388769</td>\n",
       "      <td>0.104807</td>\n",
       "      <td>0.273778</td>\n",
       "      <td>0.039738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\664ea0ccc_25/utterance_560</td>\n",
       "      <td>0.380622</td>\n",
       "      <td>0.098278</td>\n",
       "      <td>0.294232</td>\n",
       "      <td>0.094626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\664ea0ccc_14/utterance_322</td>\n",
       "      <td>0.402219</td>\n",
       "      <td>0.109847</td>\n",
       "      <td>0.338395</td>\n",
       "      <td>0.152145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\74de88564/utterance_2</td>\n",
       "      <td>0.340513</td>\n",
       "      <td>0.358777</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.891378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\e3b57cfd8_7/utterance_117</td>\n",
       "      <td>0.387916</td>\n",
       "      <td>0.106560</td>\n",
       "      <td>0.738702</td>\n",
       "      <td>-0.125857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     file_path  valence_I2  arousal_I2  valence_M2  arousal_M2\n",
       "0  \\664ea0ccc_25/utterance_580    0.388769    0.104807    0.273778    0.039738\n",
       "1  \\664ea0ccc_25/utterance_560    0.380622    0.098278    0.294232    0.094626\n",
       "2  \\664ea0ccc_14/utterance_322    0.402219    0.109847    0.338395    0.152145\n",
       "3       \\74de88564/utterance_2    0.340513    0.358777    0.079900    0.891378\n",
       "4   \\e3b57cfd8_7/utterance_117    0.387916    0.106560    0.738702   -0.125857"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = audio_test_I2.merge(video_test_M, on = 'file_path')\n",
    "# X_test = X_test.merge(audio_test_I2, on = 'file_path')\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence_indx = list(range(1,len(X_train.columns),2))\n",
    "arous_indx = list(range(2,len(X_train.columns),2))\n",
    "\n",
    "XV_train = X_train.drop(columns = ['file_path', 'arousal_M2', 'arousal_I2'])\n",
    "yV_train = actual_data_mean['valence']\n",
    "\n",
    "XA_train = X_train.drop(columns = ['file_path', 'valence_M2', 'valence_I2'])\n",
    "yA_train = actual_data_mean['arousal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "XV_test = X_test.drop(columns = ['file_path', 'arousal_M2', 'arousal_I2'])\n",
    "XA_test = X_test.drop(columns = ['file_path', 'valence_M2', 'valence_I2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XV_train, XV_val, yV_train, yV_val = train_test_split(XV_train, yV_train, test_size=0.33, random_state=42)\n",
    "# XA_train, XA_val, yA_train, yA_val = train_test_split(XA_train, yA_train, test_size=0.33, random_state=42)\n",
    "\n",
    "# XA_train.reset_index(inplace = True, drop = True)\n",
    "# XA_val.reset_index(inplace = True, drop = True)\n",
    "# yA_train.reset_index(inplace = True, drop = True)\n",
    "# yA_val.reset_index(inplace = True, drop = True)\n",
    "# XV_train.reset_index(inplace = True, drop = True)\n",
    "# XV_val.reset_index(inplace = True, drop = True)\n",
    "# yV_train.reset_index(inplace = True, drop = True)\n",
    "# yV_val.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посчитаем ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(actual, predict, class_num):\n",
    "    pred = predict[predict.columns[class_num]].values\n",
    "    act = actual[actual.columns[class_num%2]].values\n",
    "    all = len(act)\n",
    "    pos = 0\n",
    "    for i in range(len(act)):\n",
    "        a = act[i]\n",
    "        p = pred[i]\n",
    "        if abs(a - p) < 0.1:\n",
    "            pos += 1\n",
    "    return pos/all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим линейную регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_A = LinearRegression(normalize=False)\n",
    "LR_A.fit(XA_train, yA_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_V = LinearRegression(normalize=False)\n",
    "LR_V.fit(XV_train, yV_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучим LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(actual, predict, class_num):\n",
    "    pred = predict[predict.columns[class_num]].values\n",
    "    act = actual[actual.columns[class_num]].values\n",
    "    all = len(act)\n",
    "    pos = 0\n",
    "    for i in range(len(act)):\n",
    "        a = act[i]\n",
    "        p = pred[i]\n",
    "        if abs(a - p) < 0.1:\n",
    "            pos += 1\n",
    "    return pos/all\n",
    "\n",
    "def print_acc_val(act, pred):\n",
    "    val_err = error(act, pred, 0)\n",
    "    print('valence accuracy: ', val_err)\n",
    "\n",
    "    ar_err = error(act, pred, 1)\n",
    "    print('arousal accuracy: ', ar_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(XV, XA, yV, yA):\n",
    "    tree_A = LGBMRegressor(n_estimators=ESTIMATORS_A, random_state=1, learning_rate=LEARRATE_A, depth = DEPTH_V)\n",
    "    tree_A.fit(XA_train, yA_train)\n",
    "\n",
    "    tree_V = LGBMRegressor(n_estimators=ESTIMATORS_V, random_state=1, learning_rate=LEARRATE_V, depth = DEPTH_V)\n",
    "    tree_V.fit(XV_train, yV_train)\n",
    "\n",
    "    type = 'GBM'\n",
    "\n",
    "    if type == 'LR':\n",
    "        valence_pred = LR_V.predict(XV)\n",
    "        arousal_pred = LR_A.predict(XA)\n",
    "    else:\n",
    "        valence_pred = tree_V.predict(XV)\n",
    "        arousal_pred = tree_A.predict(XA)\n",
    "\n",
    "    pred_data = pd.concat([pd.DataFrame(valence_pred, columns = ['valence']),\\\n",
    "                           pd.DataFrame(arousal_pred, columns = ['arousal'])], axis = 1) \n",
    "\n",
    "    act_data = pd.concat([yV, yA], axis = 1)\n",
    "    return act_data, pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree\n"
     ]
    }
   ],
   "source": [
    "ESTIMATORS_V = 1000\n",
    "LEARRATE_V = 0.0001\n",
    "DEPTH_V = -1\n",
    "\n",
    "ESTIMATORS_A = 1000\n",
    "LEARRATE_A = 0.05\n",
    "DEPTH_A = -1\n",
    "\n",
    "if type == 'LR':\n",
    "    print('LR')\n",
    "else:\n",
    "    print('tree')\n",
    "    \n",
    "# print('val')\n",
    "# act_data, pred_data = test(XV_val, XA_val, yV_val, yA_val)\n",
    "# print_acc_val(act_data, pred_data)\n",
    "# print('train')\n",
    "# act_data, pred_data = test(XV_train, XA_train, yV_train, yA_train)\n",
    "# print_acc_val(act_data, pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       depth=-1, learning_rate=0.0001, max_depth=-1, min_child_samples=20,\n",
       "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=1000,\n",
       "       n_jobs=-1, num_leaves=31, objective=None, random_state=1,\n",
       "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "       subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_A = LGBMRegressor(n_estimators=ESTIMATORS_A, random_state=1, learning_rate=LEARRATE_A, depth = DEPTH_V)\n",
    "tree_A.fit(XA_train, yA_train)\n",
    "\n",
    "tree_V = LGBMRegressor(n_estimators=ESTIMATORS_V, random_state=1, learning_rate=LEARRATE_V, depth = DEPTH_V)\n",
    "tree_V.fit(XV_train, yV_train)\n",
    "\n",
    "# tree_V.booster_.save_model('valence_32.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели Михаила"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### аудио 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_acc(act, pred):\n",
    "    new_df = act.merge(pred, on = 'file_path')\n",
    "    val_err = error(new_df[new_df.columns[1:3]], new_df[new_df.columns[3:5]], 0)\n",
    "    print('valence accuracy: ', val_err)\n",
    "\n",
    "    ar_err = error(new_df[new_df.columns[1:3]], new_df[new_df.columns[3:5]], 1)\n",
    "    print('arousal accuracy: ', ar_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valence accuracy:  0.2345132743362832\n",
      "arousal accuracy:  0.2168141592920354\n"
     ]
    }
   ],
   "source": [
    "print_acc(actual_data_mean, audio_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Видео 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valence accuracy:  0.3495575221238938\n",
      "arousal accuracy:  0.2610619469026549\n"
     ]
    }
   ],
   "source": [
    "print_acc(actual_data_mean, video_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Ивана аудио 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valence accuracy:  0.336283185840708\n",
      "arousal accuracy:  0.2345132743362832\n"
     ]
    }
   ],
   "source": [
    "print_acc(actual_data_mean, audio_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Ивана аудио 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valence accuracy:  0.30973451327433627\n",
      "arousal accuracy:  0.2831858407079646\n"
     ]
    }
   ],
   "source": [
    "print_acc(actual_data_mean, audio_I2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_V = lgb.Booster(model_file='valence_32.txt')\n",
    "tree_A = lgb.Booster(model_file='arous_28.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == 'LR':\n",
    "    valence_pred = LR_V.predict(XV_test)\n",
    "    arousal_pred = LR_A.predict(XA_test)\n",
    "else:\n",
    "    valence_pred = tree_V.predict(XV_test)\n",
    "    arousal_pred = tree_A.predict(XA_test)\n",
    "\n",
    "pred_data = pd.concat([pd.DataFrame(valence_pred, columns = ['valence']),\\\n",
    "                       pd.DataFrame(arousal_pred, columns = ['arousal'])], axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = audio_test_I.copy()\n",
    "pred_data.valence_I1 = valence_pred \n",
    "pred_data.arousal_I1 = arousal_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.to_csv(\"prediction.txt\", sep=\" \", header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
